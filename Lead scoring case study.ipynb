{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN9Awhgpz35t"
      },
      "outputs": [],
      "source": [
        "# Supress unnecessary warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Importing the NumPy and Pandas packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "#import stats library\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#import sklearn libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report,recall_score,roc_auc_score,roc_curve,accuracy_score,precision_score,precision_recall_curve,confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#import miscellaneous libraries\n",
        "pd.set_option(\"display.max_columns\",None)\n",
        "pd.set_option(\"display.max_colwidth\",200)\n",
        "\n",
        "# Read the dataset\n",
        "leads = pd.read_csv(\"Leads.csv\")\n",
        "leads.head() \n",
        " \n",
        " #Checking the Shape of dataset\n",
        "leads.shape\n",
        "\n",
        "# Inspecting the different columns in the dataset\n",
        "leads.columns\n",
        "\n",
        "# Checking the summary of the dataset\n",
        "leads.describe()\n",
        "\n",
        "# Checking the info to see the types of the feature variables and the null values present\n",
        "leads.info()\n",
        "\n",
        "# Checking the number of missing values in each column\n",
        "leads.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# Droping all the columns in which greater than \n",
        "for c in leads.columns:\n",
        "    if leads[c].isnull().sum()>3000:\n",
        "        leads.drop(c, axis=1,inplace=True)\n",
        "\n",
        "leads.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "#checking value counts of \"City\" column\n",
        "leads['City'].value_counts(dropna=False)\n",
        "\n",
        "# dropping the \"City\" feature\n",
        "leads.drop(['City'], axis = 1, inplace = True)\n",
        "#checking value counts of \"Country\" column\n",
        "leads['Country'].value_counts(dropna=False)\n",
        "\n",
        "# dropping the \"Country\" feature\n",
        "leads.drop(['Country'], axis = 1, inplace = True)\n",
        "#Now checking the percentage of missing values in each column\n",
        "\n",
        "round(100*(leads.isnull().sum()/len(leads.index)), 2)\n",
        "\n",
        "# Checking the number of null values again\n",
        "leads.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "def countplot(x, fig):\n",
        "    plt.subplot(2,2, fig)\n",
        "    sns.countplot(leads[x])\n",
        "    plt.title('Count across'+' '+ x, size = 16)\n",
        "    plt.xlabel(x,size = 14)\n",
        "    plt.xticks(rotation = 90)\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "countplot('How did you hear about X Education',1)\n",
        "countplot('Lead Profile',2)\n",
        "countplot('Specialization',3)\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# checking the value counts of all the columns\n",
        "\n",
        "for c in leads:\n",
        "    print(leads[c].astype('category').value_counts())\n",
        "    print('___________________________________________________')\n",
        "\n",
        "\n",
        "leads['Lead Profile'].astype('category').value_counts()\n",
        "\n",
        "leads['How did you hear about X Education'].value_counts()\n",
        "\n",
        "leads['Specialization'].value_counts()\n",
        "\n",
        "def countplot(x, fig):\n",
        "    plt.subplot(4,2, fig)\n",
        "    sns.countplot(leads[x])\n",
        "    plt.title('Count across'+' '+ x, size = 16)\n",
        "    plt.xlabel(x,size = 14)\n",
        "    plt.xticks(rotation = 90)\n",
        "\n",
        "plt.figure(figsize=(18,25))\n",
        "\n",
        "\n",
        "countplot('What matters most to you in choosing a course',1)\n",
        "countplot('What is your current occupation',2)\n",
        "countplot('Specialization',3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# dropping Lead Profile and How did you hear about X Education cols\n",
        "leads.drop(['Lead Profile', 'How did you hear about X Education'], axis = 1, inplace = True)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.pairplot(leads,diag_kind='kde',hue='Converted')\n",
        "plt.show()\n",
        "\n",
        "x_edu = leads[['TotalVisits','Total Time Spent on Website','Page Views Per Visit','Converted']]\n",
        "sns.pairplot(x_edu,diag_kind='kde',hue='Converted')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "pt = PowerTransformer()\n",
        "transformedx_edu = pd.DataFrame(pt.fit_transform(x_edu))\n",
        "transformedx_edu.columns = x_edu.columns\n",
        "transformedx_edu.head()\n",
        "\n",
        "sns.pairplot(transformedx_edu,diag_kind='kde',hue='Converted')\n",
        "plt.show()\n",
        "\n",
        "# Dropping the above columns\n",
        "leads.drop(['Do Not Call', 'Search', 'Magazine', 'Newspaper Article', 'X Education Forums', 'Newspaper', \n",
        "            'Digital Advertisement', 'Through Recommendations', 'Receive More Updates About Our Courses', \n",
        "            'Update me on Supply Chain Content', 'Get updates on DM Content', \n",
        "            'I agree to pay the amount through cheque'], axis = 1, inplace = True)\n",
        "leads['What matters most to you in choosing a course'].value_counts()\n",
        "\n",
        "leads.drop(['What matters most to you in choosing a course'], axis = 1, inplace=True)\n",
        "# Checking the number of null values again\n",
        "leads.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# Dropping the null values rows in the column 'What is your current occupation'\n",
        "\n",
        "leads = leads[~pd.isnull(leads['What is your current occupation'])]\n",
        "# Observing Correlation\n",
        "# figure size\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "# heatmap\n",
        "sns.heatmap(leads.corr(), annot=True,cmap=\"BrBG\", robust=True,linewidth=0.1, vmin=-1 )\n",
        "plt.show()\n",
        "\n",
        "conv = leads.select_dtypes(include =\"object\").columns\n",
        "for i in conv:\n",
        "    \n",
        "    plt.figure(figsize =(15,5))\n",
        "    sns.countplot(leads[i], hue=leads.Converted)\n",
        "    plt.xticks(rotation = 90)\n",
        "    plt.title('Target variable in'+' '+ i)\n",
        "    plt.xlabel(i)\n",
        "    plt.show()\n",
        "\n",
        "# Checking the number of null values again\n",
        "leads.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# Dropping the null values rows in the column 'TotalVisits'\n",
        "\n",
        "leads = leads[~pd.isnull(leads['TotalVisits'])]\n",
        "# Checking the number of null values again\n",
        "leads.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# Dropping the null values rows in the column 'Lead Source'\n",
        "\n",
        "leads = leads[~pd.isnull(leads['Lead Source'])]\n",
        "# Checking the number of null values again\n",
        "leads.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# Drop the null values rows in the column 'Specialization'\n",
        "\n",
        "leads = leads[~pd.isnull(leads['Specialization'])]\n",
        "# Checking the number of null values again\n",
        "leads.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "print(len(leads.index))\n",
        "print(len(leads.index)/9240)\n",
        "\n",
        "# Let's look at the dataset again\n",
        "\n",
        "leads.head()\n",
        "\n",
        "# Dropping the \"Prospect ID\" and \"Lead Number\" \n",
        "leads.drop(['Prospect ID', 'Lead Number'], 1, inplace = True)\n",
        "leads.head()\n",
        "\n",
        "# Checking the columns which are of type 'object'\n",
        "\n",
        "temp = leads.loc[:, leads.dtypes == 'object']\n",
        "temp.columns\n",
        "\n",
        "# Demo Cell\n",
        "df = pd.DataFrame({'P': ['p', 'q', 'p']})\n",
        "df\n",
        "pd.get_dummies(df)\n",
        "\n",
        "pd.get_dummies(df, prefix=['col1'])\n",
        "\n",
        "# Creating dummy variables using the 'get_dummies' command\n",
        "dummy = pd.get_dummies(leads[['Lead Origin', 'Lead Source', 'Do Not Email', 'Last Activity',\n",
        "                              'What is your current occupation','A free copy of Mastering The Interview', \n",
        "                              'Last Notable Activity']], drop_first=True)\n",
        "\n",
        "# Add the results to the master dataframe\n",
        "leads = pd.concat([leads, dummy], axis=1)\n",
        "# Creating dummy variable separately for the variable 'Specialization' since it has the level 'Select' \n",
        "# which is useless so we\n",
        "# drop that level by specifying it explicitly\n",
        "\n",
        "dummy_spl = pd.get_dummies(leads['Specialization'], prefix = 'Specialization')\n",
        "dummy_spl = dummy_spl.drop(['Specialization_Select'], 1)\n",
        "leads = pd.concat([leads, dummy_spl], axis = 1)\n",
        "# Dropping the variables for which the dummy variables have been created\n",
        "\n",
        "leads = leads.drop(['Lead Origin', 'Lead Source', 'Do Not Email', 'Last Activity',\n",
        "                   'Specialization', 'What is your current occupation',\n",
        "                   'A free copy of Mastering The Interview', 'Last Notable Activity'], 1)\n",
        "# Let's take a look at the dataset again\n",
        "\n",
        "leads.head()\n",
        "\n",
        "# Importing the `train_test_split` library\n",
        "# Put all the feature variables in X\n",
        "\n",
        "X = leads.drop(['Converted'], 1)\n",
        "X.head()\n",
        "\n",
        "y = leads['Converted']\n",
        "\n",
        "y.head()\n",
        "\n",
        "# Spliting the dataset into 70% train and 30% test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)\n",
        "#lets check the shape\n",
        "print(\"X_train Size\", X_train.shape)\n",
        "print(\"y_train Size\", y_train.shape)\n",
        "\n",
        "# Importing the 'MinMax scaler' Library\n",
        "# Scaling the three numeric features present in the dataset\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] = scaler.fit_transform(X_train[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])\n",
        "\n",
        "X_train.head()\n",
        "\n",
        "# Looking at the correlation table\n",
        "plt.figure(figsize = (25,15))\n",
        "sns.heatmap(leads.corr())\n",
        "plt.show()\n",
        "\n",
        "# Importing the 'LogisticRegression' and creating a LogisticRegression object\n",
        "logreg = LogisticRegression()\n",
        "# Importing the 'RFE' and select 15 variables\n",
        "\n",
        "rfe = RFE(logreg, 15)             # running RFE with 15 variables as output\n",
        "rfe = rfe.fit(X_train, y_train)\n",
        "# Let's take a look at which features have been selected by RFE\n",
        "\n",
        "list(zip(X_train.columns, rfe.support_, rfe.ranking_))\n",
        "\n",
        "# Select only the columns selected by RFE\n",
        "\n",
        "X_train = X_train[col]\n",
        "# Importing 'statsmodels'\n",
        "\n",
        "# Fit a logistic Regression model on X_train after adding a constant and output the summary\n",
        "\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "logm2 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
        "res = logm2.fit()\n",
        "res.summary()\n",
        "\n",
        "# Importing the 'variance_inflation_factor' library\n",
        "# Make a VIF dataframe for all the variables present\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "vif['Features'] = X_train.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
        "vif['VIF'] = round(vif['VIF'], 2)\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif\n",
        "\n",
        "# Make a VIF dataframe for all the variables present\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "vif['Features'] = X_train.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
        "vif['VIF'] = round(vif['VIF'], 2)\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif\n",
        "\n",
        "X_train.drop('Last Notable Activity_Had a Phone Conversation', axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "# Refit the model with the new set of features\n",
        "\n",
        "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
        "logm1.fit().summary()\n",
        "\n",
        "X_train.drop('What is your current occupation_Housewife', axis = 1, inplace = True)\n",
        "\n",
        "# Refit the model with the new set of features\n",
        "\n",
        "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
        "logm1.fit().summary()\n",
        "\n",
        "X_train.drop('What is your current occupation_Working Professional', axis = 1, inplace = True)\n",
        "\n",
        "# Refit the model with the new set of features\n",
        "\n",
        "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
        "res = logm1.fit()\n",
        "res.summary()\n",
        "\n",
        "# Making a VIF dataframe for all the variables present\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "vif['Features'] = X_train.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
        "vif['VIF'] = round(vif['VIF'], 2)\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif\n",
        "\n",
        "# Use 'predict' to predict the probabilities on the train set\n",
        "\n",
        "y_train_pred = res.predict(sm.add_constant(X_train))\n",
        "y_train_pred[:10]\n",
        "\n",
        "# Reshaping it into an array\n",
        "\n",
        "y_train_pred = y_train_pred.values.reshape(-1)\n",
        "y_train_pred[:10]\n",
        "\n",
        "# Creating a new dataframe containing the actual conversion flag and the probabilities predicted by the model\n",
        "\n",
        "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Conversion_Prob':y_train_pred})\n",
        "y_train_pred_final.head()\n",
        "\n",
        "y_train_pred_final['Predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
        "\n",
        "# Let's see the head\n",
        "y_train_pred_final.head()\n",
        "\n",
        "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
        "print(confusion)\n",
        "\n",
        "# Let's check the overall accuracy\n",
        "\n",
        "print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.Predicted))\n",
        "\n",
        "# Let's evaluate the other metrics as well\n",
        "\n",
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives\n",
        "\n",
        "# Calculating the 'sensitivity'\n",
        "\n",
        "TP/(TP+FN)\n",
        "\n",
        "# Calculating the 'specificity'\n",
        "\n",
        "TN/(TN+FP)\n",
        "\n",
        "# ROC function\n",
        "\n",
        "def draw_roc( actual, probs ):\n",
        "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
        "                                              drop_intermediate = False )\n",
        "    auc_score = metrics.roc_auc_score( actual, probs )\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    return None\n",
        "\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_train_pred_final.Converted,\n",
        "                    y_train_pred_final.Conversion_Prob, \n",
        "                                         drop_intermediate=False)\n",
        "# Importing the 'matplotlib'  to plot the ROC curve`\n",
        "# Calling the ROC function\n",
        "\n",
        "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
        "\n",
        "# Let's create a dataframe to see the values of accuracy, sensitivity, and specificity at \n",
        "# different values of probabiity cutoffs\n",
        "\n",
        "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# TP = confusion[1,1] # true positive \n",
        "# TN = confusion[0,0] # true negatives\n",
        "# FP = confusion[0,1] # false positives\n",
        "# FN = confusion[1,0] # false negatives\n",
        "\n",
        "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
        "    total1=sum(sum(cm1))\n",
        "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    \n",
        "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
        "print(cutoff_df)\n",
        "\n",
        "# Let's plot it as well\n",
        "\n",
        "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
        "plt.show()\n",
        "\n",
        "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.42 else 0)\n",
        "\n",
        "y_train_pred_final.head()\n",
        "\n",
        "# Let's checking the `accuracy` now\n",
        "\n",
        "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)\n",
        "\n",
        "# Let's create the confusion matrix once again\n",
        "\n",
        "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
        "confusion2\n",
        "\n",
        "# Let's evaluate the other metrics as well\n",
        "\n",
        "TP = confusion2[1,1] # true positive \n",
        "TN = confusion2[0,0] # true negatives\n",
        "FP = confusion2[0,1] # false positives\n",
        "FN = confusion2[1,0] # false negatives\n",
        "# Calculating the 'Sensitivity'\n",
        "\n",
        "TP/(TP+FN)\n",
        "\n",
        "# Calculating the 'Specificity'\n",
        "\n",
        "TN/(TN+FP)\n",
        "\n",
        "# Scaling the test set as well using just 'transform'\n",
        "\n",
        "X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']] =  scaler.transform(X_test[['TotalVisits', 'Page Views Per Visit', 'Total Time Spent on Website']])\n",
        "# Selecting the columns in X_train for X_test as well\n",
        "\n",
        "X_test = X_test[col]\n",
        "X_test.head()\n",
        "\n",
        "# Adding a constant to X_test\n",
        "\n",
        "X_test_sm = sm.add_constant(X_test[col])\n",
        "# Checking X_test_sm\n",
        "\n",
        "X_test_sm\n",
        "\n",
        "# Dropping the required columns from X_test as well\n",
        "\n",
        "X_test.drop(['Lead Source_Reference', 'What is your current occupation_Housewife', \n",
        "             'What is your current occupation_Working Professional', \n",
        "                     'Last Notable Activity_Had a Phone Conversation'], 1, \n",
        "                                inplace = True)\n",
        "# Make predictions on the test set and store it in the variable 'y_test_pred'\n",
        "\n",
        "y_test_pred = res.predict(sm.add_constant(X_test))\n",
        "y_test_pred[:10]\n",
        "\n",
        "# Converting y_pred to a dataframe\n",
        "\n",
        "y_pred_1 = pd.DataFrame(y_test_pred)\n",
        "# Let's see the head\n",
        "\n",
        "y_pred_1.head()\n",
        "\n",
        "# Converting y_test to dataframe\n",
        "\n",
        "y_test_df = pd.DataFrame(y_test)\n",
        "# Remove index for both dataframes to append them side by side \n",
        "\n",
        "y_pred_1.reset_index(drop=True, inplace=True)\n",
        "y_test_df.reset_index(drop=True, inplace=True)\n",
        "# Append y_test_df and y_pred_1\n",
        "\n",
        "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n",
        "# Check 'y_pred_final'\n",
        "\n",
        "y_pred_final.head()\n",
        "\n",
        "# Rename the column \n",
        "\n",
        "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
        "# Let's see the head of y_pred_final\n",
        "\n",
        "y_pred_final.head()\n",
        "\n",
        "# Make predictions on the test set using 0.45 as the cutoff\n",
        "\n",
        "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.42 else 0)\n",
        "# Check y_pred_final\n",
        "\n",
        "y_pred_final.head()\n",
        "\n",
        "# Let's check the overall accuracy\n",
        "\n",
        "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)\n",
        "\n",
        "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
        "confusion2\n",
        "\n",
        "TP = confusion2[1,1] # true positive \n",
        "TN = confusion2[0,0] # true negatives\n",
        "FP = confusion2[0,1] # false positives\n",
        "FN = confusion2[1,0] # false negatives\n",
        "# Calculating the 'sensitivity'\n",
        "TP / float(TP+FN)\n",
        "\n",
        "# Calculating the 'specificity'\n",
        "TN / float(TN+FP)\n",
        "\n",
        "#Looking at the confusion matrix again\n",
        "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted )\n",
        "confusion\n",
        "\n",
        "confusion[1,1]/(confusion[0,1]+confusion[1,1])\n",
        "\n",
        "confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
        "\n",
        "y_train_pred_final.Converted, y_train_pred_final.Predicted\n",
        "\n",
        "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Conversion_Prob)\n",
        "plt.plot(thresholds, p[:-1], \"g-\")\n",
        "plt.plot(thresholds, r[:-1], \"r-\")\n",
        "plt.show()\n",
        "\n",
        "y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.44 else 0)\n",
        "\n",
        "y_train_pred_final.head()\n",
        "\n",
        "# Let's checking the `accuracy` now\n",
        "\n",
        "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)\n",
        "\n",
        "# Let's creating the confusion matrix once again\n",
        "\n",
        "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
        "confusion2\n",
        "\n",
        "# Let's evaluate the other metrics as well\n",
        "\n",
        "TP = confusion2[1,1] # true positive \n",
        "TN = confusion2[0,0] # true negatives\n",
        "FP = confusion2[0,1] # false positives\n",
        "FN = confusion2[1,0] # false negatives\n",
        "\n",
        "TP/(TP+FP)\n",
        "\n",
        "TP/(TP+FN)\n",
        "\n",
        "# Making predictions on the test set and store it in the variable 'y_test_pred'\n",
        "\n",
        "y_test_pred = res.predict(sm.add_constant(X_test))\n",
        "y_test_pred[:10]\n",
        "\n",
        "# Converting y_pred to a dataframe\n",
        "\n",
        "y_pred_1 = pd.DataFrame(y_test_pred)\n",
        "# Let's see the head\n",
        "\n",
        "y_pred_1.head()\n",
        "\n",
        "# Converting y_test to dataframe\n",
        "\n",
        "y_test_df = pd.DataFrame(y_test)\n",
        "# Removing index for both dataframes to append them side by side \n",
        "\n",
        "y_pred_1.reset_index(drop=True, inplace=True)\n",
        "y_test_df.reset_index(drop=True, inplace=True)\n",
        "# Append y_test_df and y_pred_1\n",
        "\n",
        "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n",
        "# Checking the 'y_pred_final'\n",
        "\n",
        "y_pred_final.head()\n",
        "\n",
        "# Rename the column \n",
        "\n",
        "y_pred_final= y_pred_final.rename(columns = {0 : 'Conversion_Prob'})\n",
        "# Let's see the head of y_pred_final\n",
        "\n",
        "y_pred_final.head()\n",
        "\n",
        "# Making predictions on the test set using 0.44 as the cutoff\n",
        "\n",
        "y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.44 else 0)\n",
        "# Checking y_pred_final\n",
        "\n",
        "y_pred_final.head()\n",
        "\n",
        "# Let's checking the overall accuracy\n",
        "\n",
        "metrics.accuracy_score(y_pred_final['Converted'], y_pred_final.final_predicted)\n",
        "\n",
        "confusion2 = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final.final_predicted )\n",
        "confusion2\n",
        "\n",
        "TP = confusion2[1,1] # true positive \n",
        "TN = confusion2[0,0] # true negatives\n",
        "FP = confusion2[0,1] # false positives\n",
        "FN = confusion2[1,0] # false negatives\n",
        "# Calculating the Precision\n",
        "\n",
        "TP/(TP+FP)\n",
        "\n",
        "# Calculating Recall\n",
        "\n",
        "TP/(TP+FN)"
      ]
    }
  ]
}